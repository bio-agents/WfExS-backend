from typing import (
    Sequence,
    Tuple,
)
from ply.lex import LexToken  # type: ignore[import]

from .. import (
    Child as Child,
    Fields as Fields,
    This as This,
    lexer as lexer,
    parser as parser,
)
from ..jsonpath import JSONPath

class ExtendedJsonPathLexer(lexer.JsonPathLexer):
    literals: Sequence[str]
    tokens: Tuple[str]
    t_FILTER_OP: str
    def t_BOOL(self, t: LexToken) -> LexToken: ...
    def t_SORT_DIRECTION(self, t: LexToken) -> LexToken: ...
    def t_ID(self, t: LexToken) -> LexToken: ...
    def t_FLOAT(self, t: LexToken) -> LexToken: ...

class ExtentedJsonPathParser(parser.JsonPathParser):
    tokens: Tuple[str]
    def __init__(
        self, debug: bool = ..., lexer_class: type[lexer.JsonPathLexer] = ...
    ) -> None: ...
    def p_jsonpath_operator_jsonpath(self, p: Sequence[JSONPath | str]) -> None: ...
    def p_operator(self, p: Sequence[JSONPath | str]) -> None: ...
    def p_jsonpath_named_operator(self, p: Sequence[JSONPath | str]) -> None: ...
    def p_expression(self, p: Sequence[JSONPath | str]) -> None: ...
    def p_expressions_expression(self, p: Sequence[JSONPath | str]) -> None: ...
    def p_expressions_and(self, p: Sequence[JSONPath | str]) -> None: ...
    def p_expressions_parens(self, p: Sequence[JSONPath | str]) -> None: ...
    def p_filter(self, p: Sequence[JSONPath | str]) -> None: ...
    def p_jsonpath_filter(self, p: Sequence[JSONPath | str]) -> None: ...
    def p_sort(self, p: Sequence[JSONPath | str]) -> None: ...
    def p_sorts_sort(self, p: Sequence[JSONPath | str]) -> None: ...
    def p_sorts_comma(self, p: Sequence[JSONPath | str]) -> None: ...
    def p_jsonpath_sort(self, p: Sequence[JSONPath | str]) -> None: ...
    def p_jsonpath_this(self, p: Sequence[JSONPath | str]) -> None: ...
    precedence: Sequence[Tuple[str, str] | Tuple[str, str, str]]

def parse(path: str, debug: bool = ...) -> JSONPath: ...
